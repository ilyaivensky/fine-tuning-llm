{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (4.45.2)\n",
      "Requirement already satisfied: datasets in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (3.0.1)\n",
      "Requirement already satisfied: accelerate in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (1.0.0)\n",
      "Requirement already satisfied: peft in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (0.13.1)\n",
      "Requirement already satisfied: trl in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (0.11.2)\n",
      "Requirement already satisfied: wandb in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (0.18.3)\n",
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (1.0.1)\n",
      "Requirement already satisfied: filelock in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (0.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (2.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (2024.9.11)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (0.20.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from transformers) (4.66.5)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (17.0.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (0.3.8)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (2.2.3)\n",
      "Requirement already satisfied: xxhash in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (3.5.0)\n",
      "Requirement already satisfied: multiprocess in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
      "Requirement already satisfied: aiohttp in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from datasets) (3.10.6)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: torch>=1.10.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from accelerate) (2.6.0.dev20240926)\n",
      "Requirement already satisfied: tyro>=0.5.11 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from trl) (0.8.11)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (8.1.7)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (3.1.43)\n",
      "Requirement already satisfied: platformdirs in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (3.10.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (5.28.2)\n",
      "Requirement already satisfied: sentry-sdk>=1.0.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (2.15.0)\n",
      "Requirement already satisfied: setproctitle in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (1.3.3)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from wandb) (75.1.0)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (2.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from aiohttp->datasets) (1.12.1)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from requests->transformers) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from requests->transformers) (2024.8.30)\n",
      "Requirement already satisfied: sympy==1.13.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.13.1)\n",
      "Requirement already satisfied: networkx in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from sympy==1.13.1->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: docstring-parser>=0.16 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (0.16)\n",
      "Requirement already satisfied: rich>=11.1.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (13.8.1)\n",
      "Requirement already satisfied: shtab>=1.5.6 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from pandas->datasets) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from pandas->datasets) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from pandas->datasets) (2024.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.15.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers datasets accelerate peft trl wandb python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: Skipping bitsandbytes as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# This step is needed only on Apple Metal\n",
    "!pip uninstall bitsandbytes -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "dotenv_path = Path('../.env') # path to your .env file\n",
    "load_dotenv(dotenv_path=dotenv_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33milya-ivensky\u001b[0m (\u001b[33milya-ivensky-free-lancer\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/ilyaivensky/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "WANDB_KEY=os.getenv('WANDB_KEY')\n",
    "wandb.login(key=WANDB_KEY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "\n",
    "#model_name = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"  # Replace with the appropriate Llama 3.1 model name\n",
    "model_name = \"meta-llama/Llama-3.2-1B-Instruct\"  # Replace with the appropriate Llama 3.1 model name\n",
    "\n",
    "os.environ[\"WANDB_PROJECT\"] = f\"fine-tune-{model_name.replace('/', '-')}\"  # name your W&B project\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"  # log all model checkpoints\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, torch_dtype=torch.float16)\n",
    "\n",
    "# Set up LoRA configuration\n",
    "lora_config = LoraConfig(\n",
    "    r=16,  # Low-rank dimension\n",
    "    lora_alpha=16,  # Scaling factor\n",
    "    lora_dropout=0,  # Dropout probability\n",
    "    bias=\"none\",  # Don't add bias to the LoRA adapters\n",
    "    target_modules=['down_proj', 'gate_proj', 'o_proj', 'v_proj', 'up_proj', 'q_proj', 'k_proj'],\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "# Wrap the model with LoRA\n",
    "model = get_peft_model(model, lora_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added pad_token <|eot_id|>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(128256, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if pad token exists, add it if missing\n",
    "if tokenizer.pad_token is None:\n",
    "   print(f'Added pad_token {tokenizer.eos_token}')\n",
    "   tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "tokenizer.padding_side = \"right\"\n",
    "tokenizer.is_split_into_words = True\n",
    "\n",
    "# Update the model's token embeddings to accommodate the new pad token\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS available: True\n",
      "CUDA available: False\n",
      "device=mps\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f'MPS available: {torch.backends.mps.is_available()}')\n",
    "print(f'CUDA available: {torch.cuda.is_available()}')\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = model.to(device)\n",
    "\n",
    "torch.manual_seed(42)\n",
    "print(f'device={device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['Description', 'Patient', 'Doctor'],\n",
       "    num_rows: 256916\n",
       "})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"ruslanmv/ai-medical-chatbot\", split='all')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Description': 'Q. What does abutment of the nerve root mean?',\n",
       " 'Patient': 'Hi doctor,I am just wondering what is abutting and abutment of the nerve root means in a back issue. Please explain. What treatment is required for\\xa0annular bulging and tear?',\n",
       " 'Doctor': 'Hi. I have gone through your query with diligence and would like you to know that I am here to help you. For further information consult a neurologist online -->'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask'],\n",
       "    num_rows: 256916\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpaca_propmt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "\n",
    "### Instruction: \n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "def formatting_prompt_fn(example):\n",
    "\n",
    "    instruction = example['Description'][3:] # Remove 'Q. '\n",
    "    input = example['Patient']\n",
    "    response = example['Doctor']\n",
    "\n",
    "    text = alpaca_propmt.format(instruction, input, response) + tokenizer.eos_token\n",
    "\n",
    "    return tokenizer(text)\n",
    "\n",
    "formatted_dataset = dataset.map(formatting_prompt_fn, remove_columns=['Description', 'Patient', 'Doctor'], batched=False)\n",
    "formatted_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_split = formatted_dataset.train_test_split(test_size=0.2)\n",
    "train_dataset = train_test_split['train']\n",
    "eval_dataset = train_test_split['test']\n",
    "small_eval_dataset = eval_dataset.shuffle(seed=42).select(range(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "# Define the perplexity metric function\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "\n",
    "    # Convert logits and labels from NumPy arrays to PyTorch tensors\n",
    "    logits = torch.tensor(logits)\n",
    "    labels = torch.tensor(labels)\n",
    "    \n",
    "    # Shift the labels so that they're aligned with the next token prediction\n",
    "    labels = labels[:, 1:].reshape(-1)\n",
    "    logits = logits[:, :-1].reshape(-1, logits.shape[-1])\n",
    "    \n",
    "    # Compute cross-entropy loss\n",
    "    loss_fct = torch.nn.CrossEntropyLoss()\n",
    "    loss = loss_fct(logits, labels)\n",
    "\n",
    "    # Compute perplexity from loss\n",
    "    perplexity = math.exp(loss.item()) if loss.item() < 100 else float(\"inf\")\n",
    "    \n",
    "    return {\"perplexity\": perplexity}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages/huggingface_hub/utils/_deprecation.py:100: FutureWarning: Deprecated argument(s) used in '__init__': max_seq_length. Will not be supported from version '1.0.0'.\n",
      "\n",
      "Deprecated positional argument(s) used in SFTTrainer, please use the SFTConfig to set these arguments instead.\n",
      "  warnings.warn(message, FutureWarning)\n",
      "/opt/miniconda3/envs/torch-mlx/lib/python3.12/site-packages/trl/trainer/sft_trainer.py:283: UserWarning: You passed a `max_seq_length` argument to the SFTTrainer, the value you passed will override the one in the `SFTConfig`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=\"./llama_lora_finetuned\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps = 1,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=128,\n",
    "    num_train_epochs=1,\n",
    "    save_steps=1000,\n",
    "    logging_steps=1,\n",
    "    learning_rate=1e-5,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    weight_decay=0.01,\n",
    "    warmup_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    report_to=\"wandb\",\n",
    "    seed=3407\n",
    ")\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), \n",
    "    lr=training_args.learning_rate, \n",
    "    weight_decay=training_args.weight_decay)\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    #peft_config=lora_config,\n",
    "    #dataset_text_field=\"input_ids\",\n",
    "    tokenizer=tokenizer, \n",
    "    optimizers=(optimizer, None),  # No need for a scheduler here\n",
    "    max_seq_length=tokenizer.model_max_length,\n",
    "    compute_metrics=compute_metrics,\n",
    "    packing=False,\n",
    "    #dataset_kwargs={\n",
    "    #    \"add_special_tokens\": False,\n",
    "    #    \"append_concat_token\": False,\n",
    "    #}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Changes to your `wandb` environment variables will be ignored because your `wandb` session has already started. For more information on how to modify your settings with `wandb.init()` arguments, please refer to <a href='https://wandb.me/wandb-init' target=\"_blank\">the W&B docs</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.3"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ilyaivensky/workspace/fine_tuning/notebooks/wandb/run-20241009_091754-y99fl33c</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct/runs/y99fl33c' target=\"_blank\">./llama_lora_finetuned</a></strong> to <a href='https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct' target=\"_blank\">https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct/runs/y99fl33c' target=\"_blank\">https://wandb.ai/ilya-ivensky-free-lancer/fine-tune-meta-llama-Llama-3.2-1B-Instruct/runs/y99fl33c</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "317f84b69871448288a14bc72e5eb52a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1605 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.4839, 'grad_norm': 0.6205085515975952, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dd36b83c18b4218a40692ef1c8749bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4462876319885254, 'eval_perplexity': 29.968461061195264, 'eval_runtime': 19.0327, 'eval_samples_per_second': 1.051, 'eval_steps_per_second': 1.051, 'epoch': 0.0}\n",
      "{'loss': 3.4586, 'grad_norm': 0.6195924282073975, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe72c948f2e244b18ccadcc0819fa958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.445777416229248, 'eval_perplexity': 29.95563846214156, 'eval_runtime': 28.8273, 'eval_samples_per_second': 0.694, 'eval_steps_per_second': 0.694, 'epoch': 0.0}\n",
      "{'loss': 3.427, 'grad_norm': 0.5974190831184387, 'learning_rate': 3e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1790f393637842638e9c706426c673d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4458515644073486, 'eval_perplexity': 29.957752563043176, 'eval_runtime': 85.6423, 'eval_samples_per_second': 0.234, 'eval_steps_per_second': 0.234, 'epoch': 0.0}\n",
      "{'loss': 3.4744, 'grad_norm': 0.599490225315094, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f32a9f0284348138e5d2827885d91b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4453091621398926, 'eval_perplexity': 29.94190044233763, 'eval_runtime': 63.2806, 'eval_samples_per_second': 0.316, 'eval_steps_per_second': 0.316, 'epoch': 0.0}\n",
      "{'loss': 3.4491, 'grad_norm': 0.6212579607963562, 'learning_rate': 5e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3c520678294a218e2a0fefe0db162e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4443740844726562, 'eval_perplexity': 29.914785646702878, 'eval_runtime': 70.2403, 'eval_samples_per_second': 0.285, 'eval_steps_per_second': 0.285, 'epoch': 0.0}\n",
      "{'loss': 3.4681, 'grad_norm': 0.6232648491859436, 'learning_rate': 6e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffcbd097ee964cfa8752b566017f63b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.442688465118408, 'eval_perplexity': 29.86817001825144, 'eval_runtime': 102.8323, 'eval_samples_per_second': 0.194, 'eval_steps_per_second': 0.194, 'epoch': 0.0}\n",
      "{'loss': 3.5008, 'grad_norm': 0.623978853225708, 'learning_rate': 7e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9c0a48d143be4f97add0ad0860212c21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4399242401123047, 'eval_perplexity': 29.790174635340183, 'eval_runtime': 99.8256, 'eval_samples_per_second': 0.2, 'eval_steps_per_second': 0.2, 'epoch': 0.0}\n",
      "{'loss': 3.4974, 'grad_norm': 0.6112125515937805, 'learning_rate': 8.000000000000001e-06, 'epoch': 0.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f05766e318e54146a0d4fb43c861efcf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4363837242126465, 'eval_perplexity': 29.691584544793336, 'eval_runtime': 99.6403, 'eval_samples_per_second': 0.201, 'eval_steps_per_second': 0.201, 'epoch': 0.0}\n",
      "{'loss': 3.497, 'grad_norm': 0.6269823312759399, 'learning_rate': 9e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ca4f0eb53004cf48399e1d8fda3c114",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4314169883728027, 'eval_perplexity': 29.55338480325731, 'eval_runtime': 65.433, 'eval_samples_per_second': 0.306, 'eval_steps_per_second': 0.306, 'epoch': 0.01}\n",
      "{'loss': 3.5251, 'grad_norm': 0.6304206252098083, 'learning_rate': 1e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48523049ecd945958a6f886c7c0f2e9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.425340175628662, 'eval_perplexity': 29.385735705623972, 'eval_runtime': 71.2562, 'eval_samples_per_second': 0.281, 'eval_steps_per_second': 0.281, 'epoch': 0.01}\n",
      "{'loss': 3.3942, 'grad_norm': 0.6119317412376404, 'learning_rate': 9.993730407523512e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0bf1ccef2e041cda4d3c62b2cadc54e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.418275833129883, 'eval_perplexity': 29.192633135334475, 'eval_runtime': 69.6928, 'eval_samples_per_second': 0.287, 'eval_steps_per_second': 0.287, 'epoch': 0.01}\n",
      "{'loss': 3.4418, 'grad_norm': 0.6032811999320984, 'learning_rate': 9.987460815047023e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40562a007891407ebd42bd7a795afa55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.4107518196105957, 'eval_perplexity': 28.98687738388793, 'eval_runtime': 65.4954, 'eval_samples_per_second': 0.305, 'eval_steps_per_second': 0.305, 'epoch': 0.01}\n",
      "{'loss': 3.4271, 'grad_norm': 938.4490356445312, 'learning_rate': 9.981191222570533e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e279133c1c154c3f885f0f62eda1195e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.404735565185547, 'eval_perplexity': 28.822538149226002, 'eval_runtime': 58.2904, 'eval_samples_per_second': 0.343, 'eval_steps_per_second': 0.343, 'epoch': 0.01}\n",
      "{'loss': 3.4512, 'grad_norm': 0.6245319247245789, 'learning_rate': 9.974921630094044e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7c291470ca546aeb93a0f14a348b8ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.398347854614258, 'eval_perplexity': 28.652496677200787, 'eval_runtime': 57.0653, 'eval_samples_per_second': 0.35, 'eval_steps_per_second': 0.35, 'epoch': 0.01}\n",
      "{'loss': 3.4491, 'grad_norm': 0.6270241141319275, 'learning_rate': 9.968652037617555e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91b86f21197440a89fbaaf0debf37773",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.391522169113159, 'eval_perplexity': 28.46996110142165, 'eval_runtime': 65.5853, 'eval_samples_per_second': 0.305, 'eval_steps_per_second': 0.305, 'epoch': 0.01}\n",
      "{'loss': 3.4429, 'grad_norm': 0.6250674724578857, 'learning_rate': 9.962382445141066e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c083453bfd47a3b960d06572c114a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.384915590286255, 'eval_perplexity': 28.2934853483842, 'eval_runtime': 62.0576, 'eval_samples_per_second': 0.322, 'eval_steps_per_second': 0.322, 'epoch': 0.01}\n",
      "{'loss': 3.4322, 'grad_norm': 0.6088733673095703, 'learning_rate': 9.956112852664579e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "92a4ff43d95747af9219977eec38c0cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3780887126922607, 'eval_perplexity': 28.114443430119795, 'eval_runtime': 63.1326, 'eval_samples_per_second': 0.317, 'eval_steps_per_second': 0.317, 'epoch': 0.01}\n",
      "{'loss': 3.3926, 'grad_norm': 0.6078761219978333, 'learning_rate': 9.94984326018809e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "191b2c0b27e74c2baea8a4a3ef6dba58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3712234497070312, 'eval_perplexity': 27.934349906089906, 'eval_runtime': 65.3962, 'eval_samples_per_second': 0.306, 'eval_steps_per_second': 0.306, 'epoch': 0.01}\n",
      "{'loss': 3.4511, 'grad_norm': 0.5961207151412964, 'learning_rate': 9.943573667711599e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ae0506f46dd4bf5b60f27eccd62bce6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.364393949508667, 'eval_perplexity': 27.756839408863375, 'eval_runtime': 72.0865, 'eval_samples_per_second': 0.277, 'eval_steps_per_second': 0.277, 'epoch': 0.01}\n",
      "{'loss': 3.3679, 'grad_norm': 0.6088525056838989, 'learning_rate': 9.93730407523511e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44f43c03945d45f2bf36d94f190cf0b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3573365211486816, 'eval_perplexity': 27.573697928274598, 'eval_runtime': 57.0204, 'eval_samples_per_second': 0.351, 'eval_steps_per_second': 0.351, 'epoch': 0.01}\n",
      "{'loss': 3.3867, 'grad_norm': 0.6238860487937927, 'learning_rate': 9.931034482758622e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52e43306dc924870bbda7a1ce1667923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3502273559570312, 'eval_perplexity': 27.391764827408682, 'eval_runtime': 62.4587, 'eval_samples_per_second': 0.32, 'eval_steps_per_second': 0.32, 'epoch': 0.01}\n",
      "{'loss': 3.416, 'grad_norm': 0.6212234497070312, 'learning_rate': 9.924764890282133e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "79afa4df841046ab9f62b0577e9c59d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3429551124572754, 'eval_perplexity': 27.204791762740744, 'eval_runtime': 53.8429, 'eval_samples_per_second': 0.371, 'eval_steps_per_second': 0.371, 'epoch': 0.01}\n",
      "{'loss': 3.4185, 'grad_norm': 0.6258429884910583, 'learning_rate': 9.918495297805644e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "740b58b58c304197a50917dc8f13c949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.335667371749878, 'eval_perplexity': 27.021581625055266, 'eval_runtime': 70.7195, 'eval_samples_per_second': 0.283, 'eval_steps_per_second': 0.283, 'epoch': 0.01}\n",
      "{'loss': 3.4631, 'grad_norm': 0.6170189380645752, 'learning_rate': 9.912225705329155e-06, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df40444a099941b5bc1d33aa471ae061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.32844877243042, 'eval_perplexity': 26.839611711517644, 'eval_runtime': 68.1691, 'eval_samples_per_second': 0.293, 'eval_steps_per_second': 0.293, 'epoch': 0.01}\n",
      "{'loss': 3.3584, 'grad_norm': 0.5973426699638367, 'learning_rate': 9.905956112852665e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f3f7491290943a8bb2868396715a646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.321087598800659, 'eval_perplexity': 26.657138460129627, 'eval_runtime': 57.7455, 'eval_samples_per_second': 0.346, 'eval_steps_per_second': 0.346, 'epoch': 0.02}\n",
      "{'loss': 3.3623, 'grad_norm': 0.6013031005859375, 'learning_rate': 9.899686520376176e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e0c52a37ca4edca3695a8965d4b370",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.3138535022735596, 'eval_perplexity': 26.476631711316532, 'eval_runtime': 48.6342, 'eval_samples_per_second': 0.411, 'eval_steps_per_second': 0.411, 'epoch': 0.02}\n",
      "{'loss': 3.3587, 'grad_norm': 0.6248693466186523, 'learning_rate': 9.893416927899687e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "08763592fdd248fea6931cd9c7031f4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.306919574737549, 'eval_perplexity': 26.305386331539708, 'eval_runtime': 52.74, 'eval_samples_per_second': 0.379, 'eval_steps_per_second': 0.379, 'epoch': 0.02}\n",
      "{'loss': 3.3286, 'grad_norm': 0.6103606820106506, 'learning_rate': 9.887147335423198e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c80c523ee7934390b622fd8e2f5665bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2994861602783203, 'eval_perplexity': 26.12418438930847, 'eval_runtime': 54.233, 'eval_samples_per_second': 0.369, 'eval_steps_per_second': 0.369, 'epoch': 0.02}\n",
      "{'loss': 3.4237, 'grad_norm': 0.6364954113960266, 'learning_rate': 9.880877742946709e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac2c05658b64f4e8b429331d237c858",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2922966480255127, 'eval_perplexity': 25.94853616347324, 'eval_runtime': 71.2458, 'eval_samples_per_second': 0.281, 'eval_steps_per_second': 0.281, 'epoch': 0.02}\n",
      "{'loss': 3.3424, 'grad_norm': 0.6177639961242676, 'learning_rate': 9.874608150470221e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7612ff1c98ce4e8582e982eb9ef43032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2848517894744873, 'eval_perplexity': 25.76944214137618, 'eval_runtime': 50.1222, 'eval_samples_per_second': 0.399, 'eval_steps_per_second': 0.399, 'epoch': 0.02}\n",
      "{'loss': 3.4172, 'grad_norm': 0.638789713382721, 'learning_rate': 9.86833855799373e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ae4188028ae4378a489eca6f0e8e889",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.277390718460083, 'eval_perplexity': 25.59080932714049, 'eval_runtime': 48.8885, 'eval_samples_per_second': 0.409, 'eval_steps_per_second': 0.409, 'epoch': 0.02}\n",
      "{'loss': 3.3012, 'grad_norm': 0.5967254638671875, 'learning_rate': 9.862068965517241e-06, 'epoch': 0.02}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72c4e597abaa4136a6c22e468b066e31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 3.2700819969177246, 'eval_perplexity': 25.41783826593779, 'eval_runtime': 61.6283, 'eval_samples_per_second': 0.325, 'eval_steps_per_second': 0.325, 'epoch': 0.02}\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_pretrained(\"./llama3_lora_model_finetuned\")\n",
    "tokenizer.save_pretrained(\"./llama3_lora_tokenizer_finetuned\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch-mlx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
